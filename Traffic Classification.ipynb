{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "51584b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69307a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrafficSignClassification:\n",
    "    def __init__(self, train_folder, test_folder, img_size=(32, 32), max_images_per_class=100):\n",
    "        self.train_folder = train_folder\n",
    "        self.test_folder = test_folder\n",
    "        self.img_size = img_size\n",
    "        self.max_images_per_class = max_images_per_class\n",
    "        self.data = []\n",
    "        self.labels = []\n",
    "        self.cnn_model_path = \"cnn_model.h5\"  # Path to save/load CNN model\n",
    "\n",
    "    def load_data(self, folder):\n",
    "        data = []\n",
    "        labels = []\n",
    "\n",
    "        for label in range(43):  # 43 classes (0 to 42)\n",
    "            class_folder = os.path.join(folder, str(label))\n",
    "            if not os.path.exists(class_folder):\n",
    "                print(f\"Folder {class_folder} does not exist!\")\n",
    "                continue\n",
    "\n",
    "            files = os.listdir(class_folder)\n",
    "            for idx, file in enumerate(files):\n",
    "                if idx >= self.max_images_per_class:\n",
    "                    break\n",
    "                file_path = os.path.join(class_folder, file)\n",
    "                image = cv2.imread(file_path)\n",
    "                if image is None:\n",
    "                    continue\n",
    "                image = cv2.resize(image, self.img_size)\n",
    "                data.append(image)\n",
    "                labels.append(label)\n",
    "\n",
    "        data = np.array(data, dtype=np.float32) / 255.0\n",
    "        labels = np.array(labels)\n",
    "        return data, labels\n",
    "\n",
    "    def prepare_data(self):\n",
    "        print(\"Loading training data...\")\n",
    "        self.data, self.labels = self.load_data(self.train_folder)\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(\n",
    "            self.data, self.labels, test_size=0.2, random_state=42)\n",
    "        \n",
    "        print(f\"Training data: {self.X_train.shape}\")\n",
    "        print(f\"Test data: {self.X_test.shape}\")\n",
    "\n",
    "    def grid_search(self, model, param_grid):\n",
    "        grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=3, n_jobs=-1, verbose=1)\n",
    "        X_train_flat = self.X_train.reshape(self.X_train.shape[0], -1)  # Flatten Train images\n",
    "        X_test_flat = self.X_test.reshape(self.X_test.shape[0], -1)  # Also Flatten Test images\n",
    "\n",
    "        grid_search.fit(X_train_flat, self.y_train)\n",
    "        best_model = grid_search.best_estimator_\n",
    "\n",
    "        print(f\"Best parameters for {model.__class__.__name__}: {grid_search.best_params_}\")\n",
    "        \n",
    "        predictions = best_model.predict(X_test_flat)\n",
    "        print(f\"Classification Report:\\n{classification_report(self.y_test, predictions)}\")\n",
    "        print(f\"Confusion Matrix:\\n{confusion_matrix(self.y_test, predictions)}\")\n",
    "\n",
    "        return best_model\n",
    "\n",
    "    def train_svm(self):\n",
    "        param_grid = {\n",
    "            'C': [0.1, 1, 10],\n",
    "            'kernel': ['rbf'],\n",
    "            'gamma': ['scale', 'auto']\n",
    "        }\n",
    "        svm = SVC()\n",
    "        best_svm_model = self.grid_search(svm, param_grid)\n",
    "        \n",
    "        # Save the SVM model after training\n",
    "        with open('svm_model.pkl', 'wb') as f:\n",
    "            pickle.dump(best_svm_model, f)\n",
    "        print(\"SVM model saved as svm_model.pkl\")\n",
    "        \n",
    "        return best_svm_model\n",
    "\n",
    "    def train_knn(self):\n",
    "        param_grid = {\n",
    "            'n_neighbors': [3, 5, 7, 9]\n",
    "        }\n",
    "        knn = KNeighborsClassifier()\n",
    "        best_knn_model = self.grid_search(knn, param_grid)\n",
    "        \n",
    "        # Save the KNN model after training\n",
    "        with open('knn_model.pkl', 'wb') as f:\n",
    "            pickle.dump(best_knn_model, f)\n",
    "        print(\"KNN model saved as knn_model.pkl\")\n",
    "        return best_knn_model\n",
    "\n",
    "    def train_decision_tree(self):\n",
    "        param_grid = {\n",
    "            'max_depth': [None, 10, 20, 30],\n",
    "            'min_samples_split': [2, 5, 10],\n",
    "            'min_samples_leaf': [1, 2, 4]\n",
    "        }\n",
    "        decision_tree = DecisionTreeClassifier()\n",
    "        best_tree_model = self.grid_search(decision_tree, param_grid)\n",
    "        \n",
    "        # Save the Decision Tree model after training\n",
    "        with open('decision_tree_model.pkl', 'wb') as f:\n",
    "            pickle.dump(best_tree_model, f)\n",
    "        print(\"Decision Tree model saved as decision_tree_model.pkl\")\n",
    "        return best_tree_model\n",
    "\n",
    "    def train_random_forest(self):\n",
    "        param_grid = {\n",
    "            'n_estimators': [50, 100, 200],\n",
    "            'max_depth': [None, 10, 20, 30],\n",
    "            'min_samples_split': [2, 5, 10],\n",
    "            'min_samples_leaf': [1, 2, 4]\n",
    "        }\n",
    "        random_forest = RandomForestClassifier()\n",
    "        best_forest_model = self.grid_search(random_forest, param_grid)\n",
    "        \n",
    "        # Save the Random Forest model after training\n",
    "        with open('random_forest_model.pkl', 'wb') as f:\n",
    "            pickle.dump(best_forest_model, f)\n",
    "        print(\"Random Forest  model saved as random_forest_model.pkl\")\n",
    "        return best_forest_model\n",
    "\n",
    "    def train_softmax_regression(self):\n",
    "        param_grid = {\n",
    "            'C': [0.1, 1, 10],\n",
    "            'max_iter': [100, 200, 300]\n",
    "        }\n",
    "        logistic = LogisticRegression(multi_class='multinomial', max_iter=1000)\n",
    "        best_softmax_model = self.grid_search(logistic, param_grid)\n",
    "        \n",
    "        # Save the Softmax Regression model after training\n",
    "        with open('softmax_model.pkl', 'wb') as f:\n",
    "            pickle.dump(best_softmax_model, f)\n",
    "        print(\"Softmax Regression model saved as softmax_model.pkl\")\n",
    "        return best_softmax_model\n",
    "\n",
    "    def train_cnn(self):\n",
    "        y_train_categorical = to_categorical(self.y_train, 43)\n",
    "        y_test_categorical = to_categorical(self.y_test, 43)\n",
    "\n",
    "        model = Sequential([\n",
    "            Conv2D(32, (3, 3), activation='relu', input_shape=(self.img_size[0], self.img_size[1], 3)),\n",
    "            MaxPooling2D((2, 2)),\n",
    "            Conv2D(64, (3, 3), activation='relu'),\n",
    "            MaxPooling2D((2, 2)),\n",
    "            Flatten(),\n",
    "            Dense(128, activation='relu'),\n",
    "            Dropout(0.5),\n",
    "            Dense(43, activation='softmax')\n",
    "        ])\n",
    "        model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "                      loss='categorical_crossentropy',\n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "        history = model.fit(self.X_train, y_train_categorical,\n",
    "                            validation_data=(self.X_test, y_test_categorical),\n",
    "                            epochs=10, batch_size=32, verbose=1)\n",
    "\n",
    "        _, accuracy = model.evaluate(self.X_test, y_test_categorical, verbose=0)\n",
    "        print(f\"CNN Accuracy: {accuracy * 100:.2f}%\")\n",
    "        \n",
    "        # Save the CNN model to a file\n",
    "        model.save(self.cnn_model_path)\n",
    "        print(f\"CNN model saved as {self.cnn_model_path}\")\n",
    "        self.cnn_model = model\n",
    "        \n",
    "    def load_cnn_model(self):\n",
    "        if os.path.exists(self.cnn_model_path):\n",
    "            self.cnn_model = load_model(self.cnn_model_path)\n",
    "            print(f\"CNN model loaded from {self.cnn_model_path}\")\n",
    "        else:\n",
    "            print(f\"CNN model file {self.cnn_model_path} does not exist. Train the model first.\")\n",
    "\n",
    "    def visualize_samples(self):\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        for i in range(9):\n",
    "            plt.subplot(3, 3, i + 1)\n",
    "            plt.imshow(self.X_train[i])\n",
    "            plt.title(f\"Label: {self.y_train[i]}\")\n",
    "            plt.axis(\"off\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9db464ae",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training data...\n",
      "Training data: (3440, 32, 32, 3)\n",
      "Test data: (860, 32, 32, 3)\n",
      "Training SVM model...\n",
      "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n",
      "Best parameters for SVC: {'C': 10, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        24\n",
      "           1       1.00      1.00      1.00        24\n",
      "           2       1.00      1.00      1.00        25\n",
      "           3       1.00      1.00      1.00        18\n",
      "           4       1.00      0.81      0.89        21\n",
      "           5       1.00      1.00      1.00        21\n",
      "           6       1.00      0.94      0.97        18\n",
      "           7       1.00      0.95      0.97        20\n",
      "           8       0.88      1.00      0.94        22\n",
      "           9       1.00      1.00      1.00        13\n",
      "          10       1.00      1.00      1.00        25\n",
      "          11       0.86      0.96      0.91        25\n",
      "          12       0.90      1.00      0.95        26\n",
      "          13       0.78      1.00      0.88        18\n",
      "          14       1.00      1.00      1.00        25\n",
      "          15       0.96      1.00      0.98        22\n",
      "          16       1.00      1.00      1.00        19\n",
      "          17       1.00      1.00      1.00        11\n",
      "          18       1.00      1.00      1.00        22\n",
      "          19       1.00      1.00      1.00        21\n",
      "          20       1.00      0.95      0.97        20\n",
      "          21       1.00      1.00      1.00        19\n",
      "          22       1.00      0.91      0.95        23\n",
      "          23       1.00      1.00      1.00        15\n",
      "          24       1.00      0.96      0.98        24\n",
      "          25       1.00      0.96      0.98        24\n",
      "          26       1.00      1.00      1.00        27\n",
      "          27       1.00      1.00      1.00        11\n",
      "          28       1.00      1.00      1.00        16\n",
      "          29       1.00      0.93      0.97        15\n",
      "          30       1.00      0.94      0.97        18\n",
      "          31       1.00      1.00      1.00        15\n",
      "          32       1.00      0.95      0.98        21\n",
      "          33       0.93      1.00      0.97        14\n",
      "          34       1.00      1.00      1.00        17\n",
      "          35       1.00      0.95      0.98        21\n",
      "          36       1.00      1.00      1.00        22\n",
      "          37       1.00      1.00      1.00        12\n",
      "          38       1.00      1.00      1.00        18\n",
      "          39       0.96      1.00      0.98        25\n",
      "          40       1.00      0.96      0.98        28\n",
      "          41       1.00      1.00      1.00        17\n",
      "          42       1.00      0.94      0.97        18\n",
      "\n",
      "    accuracy                           0.98       860\n",
      "   macro avg       0.98      0.98      0.98       860\n",
      "weighted avg       0.98      0.98      0.98       860\n",
      "\n",
      "Confusion Matrix:\n",
      "[[24  0  0 ...  0  0  0]\n",
      " [ 0 24  0 ...  0  0  0]\n",
      " [ 0  0 25 ...  0  0  0]\n",
      " ...\n",
      " [ 0  0  0 ... 27  0  0]\n",
      " [ 0  0  0 ...  0 17  0]\n",
      " [ 0  0  0 ...  0  0 17]]\n",
      "SVM model saved as svm_model.pkl\n",
      "Training KNN model...\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "Best parameters for KNeighborsClassifier: {'n_neighbors': 3}\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        24\n",
      "           1       0.79      0.96      0.87        24\n",
      "           2       0.82      0.92      0.87        25\n",
      "           3       0.72      0.72      0.72        18\n",
      "           4       0.84      1.00      0.91        21\n",
      "           5       0.81      1.00      0.89        21\n",
      "           6       0.95      1.00      0.97        18\n",
      "           7       0.91      1.00      0.95        20\n",
      "           8       0.92      1.00      0.96        22\n",
      "           9       0.92      0.92      0.92        13\n",
      "          10       1.00      1.00      1.00        25\n",
      "          11       0.94      0.68      0.79        25\n",
      "          12       0.92      0.88      0.90        26\n",
      "          13       0.62      1.00      0.77        18\n",
      "          14       1.00      0.96      0.98        25\n",
      "          15       1.00      0.86      0.93        22\n",
      "          16       1.00      1.00      1.00        19\n",
      "          17       1.00      1.00      1.00        11\n",
      "          18       0.91      0.95      0.93        22\n",
      "          19       0.88      1.00      0.93        21\n",
      "          20       0.79      0.95      0.86        20\n",
      "          21       1.00      1.00      1.00        19\n",
      "          22       0.95      0.83      0.88        23\n",
      "          23       1.00      1.00      1.00        15\n",
      "          24       0.91      0.83      0.87        24\n",
      "          25       1.00      0.79      0.88        24\n",
      "          26       1.00      0.89      0.94        27\n",
      "          27       0.85      1.00      0.92        11\n",
      "          28       0.94      1.00      0.97        16\n",
      "          29       1.00      0.87      0.93        15\n",
      "          30       1.00      0.94      0.97        18\n",
      "          31       1.00      1.00      1.00        15\n",
      "          32       0.95      0.95      0.95        21\n",
      "          33       1.00      1.00      1.00        14\n",
      "          34       0.94      0.94      0.94        17\n",
      "          35       1.00      0.90      0.95        21\n",
      "          36       0.81      0.95      0.88        22\n",
      "          37       1.00      1.00      1.00        12\n",
      "          38       1.00      0.89      0.94        18\n",
      "          39       1.00      0.96      0.98        25\n",
      "          40       1.00      0.68      0.81        28\n",
      "          41       1.00      0.71      0.83        17\n",
      "          42       1.00      0.94      0.97        18\n",
      "\n",
      "    accuracy                           0.92       860\n",
      "   macro avg       0.93      0.93      0.93       860\n",
      "weighted avg       0.93      0.92      0.92       860\n",
      "\n",
      "Confusion Matrix:\n",
      "[[24  0  0 ...  0  0  0]\n",
      " [ 0 23  0 ...  0  0  0]\n",
      " [ 0  0 23 ...  0  0  0]\n",
      " ...\n",
      " [ 0  0  1 ... 19  0  0]\n",
      " [ 0  0  0 ...  0 12  0]\n",
      " [ 0  0  0 ...  0  0 17]]\n",
      "KNN model saved as knn_model.pkl\n",
      "Training Decision Tree model...\n",
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n",
      "Best parameters for DecisionTreeClassifier: {'max_depth': 30, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.75      0.77        24\n",
      "           1       0.76      0.54      0.63        24\n",
      "           2       0.59      0.52      0.55        25\n",
      "           3       0.62      0.83      0.71        18\n",
      "           4       0.67      0.86      0.75        21\n",
      "           5       0.68      0.81      0.74        21\n",
      "           6       1.00      0.83      0.91        18\n",
      "           7       0.68      0.75      0.71        20\n",
      "           8       0.93      0.64      0.76        22\n",
      "           9       0.56      0.77      0.65        13\n",
      "          10       0.80      0.80      0.80        25\n",
      "          11       0.91      0.80      0.85        25\n",
      "          12       0.68      0.50      0.58        26\n",
      "          13       0.48      0.72      0.58        18\n",
      "          14       0.96      0.92      0.94        25\n",
      "          15       0.76      0.86      0.81        22\n",
      "          16       0.89      0.84      0.86        19\n",
      "          17       0.83      0.91      0.87        11\n",
      "          18       0.82      0.82      0.82        22\n",
      "          19       0.69      0.95      0.80        21\n",
      "          20       0.84      0.80      0.82        20\n",
      "          21       1.00      0.89      0.94        19\n",
      "          22       0.77      0.87      0.82        23\n",
      "          23       0.67      0.40      0.50        15\n",
      "          24       0.81      0.71      0.76        24\n",
      "          25       0.72      0.88      0.79        24\n",
      "          26       0.88      0.81      0.85        27\n",
      "          27       0.80      0.73      0.76        11\n",
      "          28       0.75      0.75      0.75        16\n",
      "          29       0.53      0.53      0.53        15\n",
      "          30       0.76      0.72      0.74        18\n",
      "          31       0.82      0.60      0.69        15\n",
      "          32       0.95      0.95      0.95        21\n",
      "          33       1.00      0.86      0.92        14\n",
      "          34       0.88      0.88      0.88        17\n",
      "          35       0.94      0.76      0.84        21\n",
      "          36       0.67      0.55      0.60        22\n",
      "          37       0.83      0.83      0.83        12\n",
      "          38       0.72      1.00      0.84        18\n",
      "          39       0.85      0.92      0.88        25\n",
      "          40       0.92      0.86      0.89        28\n",
      "          41       0.77      0.59      0.67        17\n",
      "          42       0.54      0.78      0.64        18\n",
      "\n",
      "    accuracy                           0.77       860\n",
      "   macro avg       0.78      0.77      0.77       860\n",
      "weighted avg       0.78      0.77      0.77       860\n",
      "\n",
      "Confusion Matrix:\n",
      "[[18  0  0 ...  0  0  0]\n",
      " [ 1 13  4 ...  0  0  0]\n",
      " [ 0  1 13 ...  0  0  0]\n",
      " ...\n",
      " [ 0  0  0 ... 24  0  1]\n",
      " [ 0  0  0 ...  0 10  1]\n",
      " [ 0  0  0 ...  1  0 14]]\n",
      "Decision Tree model saved as decision_tree_model.pkl\n",
      "Training Random Forest model...\n",
      "Fitting 3 folds for each of 108 candidates, totalling 324 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for RandomForestClassifier: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        24\n",
      "           1       1.00      0.96      0.98        24\n",
      "           2       0.96      1.00      0.98        25\n",
      "           3       0.86      1.00      0.92        18\n",
      "           4       1.00      1.00      1.00        21\n",
      "           5       1.00      1.00      1.00        21\n",
      "           6       1.00      0.94      0.97        18\n",
      "           7       1.00      1.00      1.00        20\n",
      "           8       1.00      1.00      1.00        22\n",
      "           9       1.00      1.00      1.00        13\n",
      "          10       1.00      1.00      1.00        25\n",
      "          11       1.00      0.92      0.96        25\n",
      "          12       1.00      1.00      1.00        26\n",
      "          13       0.90      1.00      0.95        18\n",
      "          14       1.00      1.00      1.00        25\n",
      "          15       1.00      1.00      1.00        22\n",
      "          16       1.00      1.00      1.00        19\n",
      "          17       1.00      1.00      1.00        11\n",
      "          18       1.00      1.00      1.00        22\n",
      "          19       1.00      1.00      1.00        21\n",
      "          20       1.00      0.95      0.97        20\n",
      "          21       1.00      1.00      1.00        19\n",
      "          22       1.00      1.00      1.00        23\n",
      "          23       1.00      1.00      1.00        15\n",
      "          24       1.00      0.96      0.98        24\n",
      "          25       1.00      0.96      0.98        24\n",
      "          26       1.00      1.00      1.00        27\n",
      "          27       1.00      1.00      1.00        11\n",
      "          28       1.00      1.00      1.00        16\n",
      "          29       0.94      1.00      0.97        15\n",
      "          30       0.95      1.00      0.97        18\n",
      "          31       0.88      0.93      0.90        15\n",
      "          32       1.00      0.95      0.98        21\n",
      "          33       1.00      1.00      1.00        14\n",
      "          34       1.00      1.00      1.00        17\n",
      "          35       1.00      1.00      1.00        21\n",
      "          36       1.00      1.00      1.00        22\n",
      "          37       1.00      1.00      1.00        12\n",
      "          38       1.00      1.00      1.00        18\n",
      "          39       1.00      1.00      1.00        25\n",
      "          40       1.00      1.00      1.00        28\n",
      "          41       0.94      1.00      0.97        17\n",
      "          42       1.00      0.89      0.94        18\n",
      "\n",
      "    accuracy                           0.99       860\n",
      "   macro avg       0.99      0.99      0.99       860\n",
      "weighted avg       0.99      0.99      0.99       860\n",
      "\n",
      "Confusion Matrix:\n",
      "[[24  0  0 ...  0  0  0]\n",
      " [ 0 23  0 ...  0  0  0]\n",
      " [ 0  0 25 ...  0  0  0]\n",
      " ...\n",
      " [ 0  0  0 ... 28  0  0]\n",
      " [ 0  0  0 ...  0 17  0]\n",
      " [ 0  0  0 ...  0  1 16]]\n",
      "Random Forest  model saved as random_forest_model.pkl\n",
      "Training CNN model...\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mr\\anaconda3\\lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.0510 - loss: 3.6860 - val_accuracy: 0.4302 - val_loss: 2.6199\n",
      "Epoch 2/10\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.3473 - loss: 2.4820 - val_accuracy: 0.7279 - val_loss: 1.1968\n",
      "Epoch 3/10\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6082 - loss: 1.3878 - val_accuracy: 0.8616 - val_loss: 0.6580\n",
      "Epoch 4/10\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7239 - loss: 0.9306 - val_accuracy: 0.9279 - val_loss: 0.3935\n",
      "Epoch 5/10\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8090 - loss: 0.6527 - val_accuracy: 0.9512 - val_loss: 0.2857\n",
      "Epoch 6/10\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8520 - loss: 0.4973 - val_accuracy: 0.9698 - val_loss: 0.1790\n",
      "Epoch 7/10\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8959 - loss: 0.3676 - val_accuracy: 0.9826 - val_loss: 0.1216\n",
      "Epoch 8/10\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9041 - loss: 0.3181 - val_accuracy: 0.9802 - val_loss: 0.1037\n",
      "Epoch 9/10\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9219 - loss: 0.2656 - val_accuracy: 0.9895 - val_loss: 0.0729\n",
      "Epoch 10/10\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9379 - loss: 0.2267 - val_accuracy: 0.9860 - val_loss: 0.0622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN Accuracy: 98.60%\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "`save_model()` using h5 format requires h5py. Could not import h5py.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 28\u001b[0m\n\u001b[0;32m     25\u001b[0m forest_model \u001b[38;5;241m=\u001b[39m classifier\u001b[38;5;241m.\u001b[39mtrain_random_forest()\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining CNN model...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 28\u001b[0m cnn_model \u001b[38;5;241m=\u001b[39m \u001b[43mclassifier\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_cnn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining Softmax Regression model...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     31\u001b[0m softmax_model \u001b[38;5;241m=\u001b[39m classifier\u001b[38;5;241m.\u001b[39mtrain_softmax_regression()\n",
      "Cell \u001b[1;32mIn[7], line 162\u001b[0m, in \u001b[0;36mTrafficSignClassification.train_cnn\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    159\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCNN Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracy\u001b[38;5;250m \u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m100\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    161\u001b[0m \u001b[38;5;66;03m# Save the CNN model to a file\u001b[39;00m\n\u001b[1;32m--> 162\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcnn_model_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    163\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCNN model saved as \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcnn_model_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcnn_model \u001b[38;5;241m=\u001b[39m model\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\src\\legacy\\saving\\legacy_h5_format.py:28\u001b[0m, in \u001b[0;36msave_model_to_hdf5\u001b[1;34m(model, filepath, overwrite, include_optimizer)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msave_model_to_hdf5\u001b[39m(model, filepath, overwrite\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, include_optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m h5py \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 28\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[0;32m     29\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`save_model()` using h5 format requires h5py. Could not \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     30\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimport h5py.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     31\u001b[0m         )\n\u001b[0;32m     33\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(filepath, h5py\u001b[38;5;241m.\u001b[39mFile):\n\u001b[0;32m     34\u001b[0m         \u001b[38;5;66;03m# If file exists and should not be overwritten.\u001b[39;00m\n\u001b[0;32m     35\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m overwrite \u001b[38;5;129;01mand\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misfile(filepath):\n",
      "\u001b[1;31mImportError\u001b[0m: `save_model()` using h5 format requires h5py. Could not import h5py."
     ]
    }
   ],
   "source": [
    "# Paths of train and test data folders\n",
    "csv_train = \"train.csv\"\n",
    "csv_test = \"test.csv\"\n",
    "test_folder = r\"E:\\DataScience BootCamp\\Ayad_Collection\\Udemy\\Projects\\Computer Vision\\Computetr Vision\\Traffic Classification\\Test\"\n",
    "train_folder = r\"E:\\DataScience BootCamp\\Ayad_Collection\\Udemy\\Projects\\Computer Vision\\Computetr Vision\\Traffic Classification\\Train\"\n",
    "\n",
    "\n",
    "# Initialize the TrafficSignClassification object\n",
    "classifier = TrafficSignClassification(train_folder, test_folder)\n",
    "\n",
    "# Prepare the data\n",
    "classifier.prepare_data()\n",
    "\n",
    "# Train and evaluate the SVM model\n",
    "print(\"Training SVM model...\")\n",
    "svm_model = classifier.train_svm()\n",
    "\n",
    "print(\"Training KNN model...\")\n",
    "knn_model = classifier.train_knn()\n",
    "\n",
    "print(\"Training Decision Tree model...\")\n",
    "tree_model = classifier.train_decision_tree()\n",
    "\n",
    "print(\"Training Random Forest model...\")\n",
    "forest_model = classifier.train_random_forest()\n",
    "\n",
    "print(\"Training CNN model...\")\n",
    "cnn_model = classifier.train_cnn()\n",
    "\n",
    "print(\"Training Softmax Regression model...\")\n",
    "softmax_model = classifier.train_softmax_regression()\n",
    "\n",
    "classifier.visualize_samples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "208041c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('knn_model.pkl', 'rb') as f:\n",
    "    knn_model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b276bf82",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('random_forest_model.pkl', 'rb') as f:\n",
    "    random_forest_model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0ac75d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('decision_tree_model.pkl', 'rb') as f:\n",
    "    decision_tree_model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ae56bf51",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'softmax_model.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msoftmax_model.pkl\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m      2\u001b[0m     softmax_model \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(f)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:282\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    275\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    276\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    277\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    278\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    279\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    280\u001b[0m     )\n\u001b[1;32m--> 282\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m io_open(file, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'softmax_model.pkl'"
     ]
    }
   ],
   "source": [
    "with open('softmax_model.pkl', 'rb') as f:\n",
    "    softmax_model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6f8383f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('svm_model.pkl', 'rb') as f:\n",
    "    svm_model = pickle.load(f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
